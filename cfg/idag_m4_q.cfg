[net]
batch=128
subdivisions=1
height=21
width=21
channels=1
decay=0.0001
clip=0.1

optimizer=sgd
momentum=0.9

# optimizer=adam
# B1=0.9
# B2=0.999
# eps=0.0000001

learning_rate=0.1
policy=steps
steps=50000,100000,150000
scales=.1,.1,.1
max_batches=200000

[convolutional]
name=conv1
batch_normalize=0
filters=48
size=3
stride=1
pad=1
activation=relu
weight_transform_scheme=wts_uniform
wts_num_level=256
wts_step_size=0.015625
# quantization_scheme=qs_root
qs_num_level=256
qs_step_size=0.003906250000

[convolutional]
name=conv2
batch_normalize=0
filters=24
size=1		
stride=1
pad=0
activation=relu
weight_transform_scheme=wts_uniform
wts_num_level=256
wts_step_size=0.0078125
# quantization_scheme=qs_root
qs_num_level=256
qs_step_size=0.003906250000

[convolutional]
name=conv3
batch_normalize=0
filters=16
size=3
stride=1
pad=1
activation=relu
weight_transform_scheme=wts_uniform
wts_num_level=256
wts_step_size=0.0078125
# quantization_scheme=qs_root
qs_num_level=256
qs_step_size=0.003906250000

[convolutional]
name=conv4
batch_normalize=0
filters=24
size=3
stride=1
pad=1
activation=relu
weight_transform_scheme=wts_uniform
wts_num_level=256
wts_step_size=0.015625
# quantization_scheme=qs_root
qs_num_level=256
qs_step_size=0.003906250000

[convolutional]
name=conv5
batch_normalize=0
filters=16
size=3
stride=1
pad=1
activation=relu
weight_transform_scheme=wts_uniform
wts_num_level=256
wts_step_size=0.0078125
# quantization_scheme=qs_root
qs_num_level=256
qs_step_size=0.003906250000

[convolutional]
name=conv6
batch_normalize=0
filters=24
size=3
stride=1
pad=1
activation=relu
weight_transform_scheme=wts_uniform
wts_num_level=256
wts_step_size=0.0078125
# quantization_scheme=qs_root
qs_num_level=256
qs_step_size=0.003906250000

[convolutional]
name=conv7
batch_normalize=0
filters=48
size=1		
stride=1
pad=0
activation=relu
weight_transform_scheme=wts_uniform
wts_num_level=256
wts_step_size=0.00390625
# quantization_scheme=qs_root
qs_num_level=256
qs_step_size=0.001953125000

[convolutional]
name=conv8
batch_normalize=0
filters=4
size=3
stride=1
pad=1
activation=linear

[stack]
root_connect=1
stride=4

[shortcut]
from=-2
activation=linear

[sr_flat]

[cost]
type=sse